import transformers
from transformers import AutoTokenizer
import json

# ======================================================
# 1. è®¾ç½®æ¨¡å‹è·¯å¾„ & åŠ è½½åˆ†è¯å™¨
# ======================================================
MODEL_PATH = "/home/zjusst/hxy/llada/models/GSAI-ML/LLaDA-8B-Instruct"
print(f"ğŸ”„ æ­£åœ¨ä»æœ¬åœ°åŠ è½½åˆ†è¯å™¨: {MODEL_PATH}")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    print("âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    exit()

# ======================================================
# 2. ã€å…³é”®ã€‘ç›´æ¥å¤åˆ¶è®­ç»ƒä»£ç é‡Œçš„æ ¸å¿ƒå‡½æ•°
#    (è¿™å°±æ˜¯â€œå¯¹é½â€çš„æ ¸å¿ƒï¼šä¿è¯é€»è¾‘ä»£ç ä¸€ä¸ªå­—éƒ½ä¸å˜)
# ======================================================
def default_mdlm_sft_map_fn(row, *, tokenizer, mask_prompt_loss: bool = True) -> dict:
    """
    Build input_ids and labels for SFT.
    (è¿™æ˜¯ä½  SFT.py é‡ŒåŸæœ¬çš„å‡½æ•°ï¼ŒåŸå°ä¸åŠ¨å¤åˆ¶è¿‡æ¥çš„)
    """
    # 1. ç”Ÿæˆå®Œæ•´çš„ [Prompt + Response]
    prompt_response_tokens = tokenizer.apply_chat_template(
        row["messages"], tokenize=True, add_generation_prompt=False
    )
    labels = prompt_response_tokens.copy()

    if mask_prompt_loss:
        # 2. è¿™é‡Œçš„é€»è¾‘ï¼šadd_generation_prompt=True 
        #    è¿™æ„å‘³ç€å®ƒä¼šè‡ªåŠ¨è®¡ç®— User + å›ºå®šçš„ Assistant å¤´éƒ¨çš„é•¿åº¦
        prompt_tokens = tokenizer.apply_chat_template(
            row["messages"][:-1], tokenize=True, add_generation_prompt=True
        )
        
        # 3. Masking
        prompt_len = len(prompt_tokens)
        labels[: prompt_len] = [-100] * prompt_len
        
        return {
            "input_ids": prompt_response_tokens,
            "labels": labels,
            "prompt_len": prompt_len,
        }

    return {"input_ids": prompt_response_tokens, "labels": labels}

# ======================================================
# 3. å¯è§†åŒ–è¯Šæ–­å‡½æ•°
# ======================================================
def diagnose_masking(sample_data):
    print("\n" + "="*80)
    print(" ğŸ§ª SFT æ•°æ® Masking çœŸå®å¯¹é½æµ‹è¯•")
    print("="*80)

    # --- è°ƒç”¨æ ¸å¿ƒå‡½æ•° ---
    # è¿™å®Œå…¨æ¨¡æ‹Ÿäº† Dataset.map é‡Œçš„è¡Œä¸º
    processed = default_mdlm_sft_map_fn(
        sample_data, 
        tokenizer=tokenizer, 
        mask_prompt_loss=True
    )
    
    input_ids = processed['input_ids']
    labels = processed['labels']
    
    # --- æ‰“å°è¾¹ç•Œè¯Šæ–­ ---
    print(f"Input æ€»é•¿åº¦: {len(input_ids)}")
    print(f"Prompt é•¿åº¦ : {processed['prompt_len']} (è¿™äº›å°†è¢« Mask)")
    
    # æ‰¾åˆ° Mask å’Œ Train çš„äº¤ç•Œå¤„
    first_train_idx = processed['prompt_len']
    
    print("\nã€äº¤ç•Œå¤„æ˜¾å¾®é•œã€‘(å±•ç¤ºäº¤ç•Œå¤„å‰åçš„ Token)")
    print(f"{'ä½ç½®':<6} | {'ID':<8} | {'Token (è§£ç )':<25} | {'Label':<10} | {'çŠ¶æ€'}")
    print("-" * 80)
    
    # æˆ‘ä»¬åªçœ‹äº¤ç•Œå¤„å‰å 5 ä¸ª tokenï¼Œè¿™æœ€å…³é”®
    start_view = max(0, first_train_idx - 5)
    end_view = min(len(input_ids), first_train_idx + 10)
    
    for i in range(start_view, end_view):
        tid = input_ids[i]
        lbl = labels[i]
        
        token_str = tokenizer.decode([tid]).replace("\n", "\\n")
        # ç¼©ç•¥è¿‡é•¿çš„å­—ç¬¦ä¸²
        if len(token_str) > 20: token_str = token_str[:20] + "..."
        token_str = f"'{token_str}'"
        
        if lbl == -100:
            label_disp = "ğŸš« -100"
            status = "Masked (Prompt)"
        else:
            label_disp = f"âœ… {lbl}"
            status = "Train (Answer)"
            
        # é«˜äº®äº¤ç•Œçº¿
        if i == first_train_idx:
            print("-" * 80 + " <--- è®­ç»ƒå¼€å§‹çº¿ (Loss Start)")
            
        print(f"{i:<6} | {tid:<8} | {token_str:<25} | {label_disp:<10} | {status}")
    
    print("-" * 80)

# ======================================================
# 4. æ³¨å…¥ä½ çš„çœŸå®æ•°æ®
# ======================================================
# è¿™æ˜¯ä½ ä¹‹å‰ç»™å‡ºçš„ TableDreamer çœŸå®æ•°æ®
real_data = {
    "item_id": "TableDreamer_train_data_1883", 
    "messages": [
        {
            "role": "user", 
            "content": "Convert all 'Initial Fuel' and 'Altered Fuel' data from liters to US gallons...\n(æ­¤å¤„çœç•¥é•¿æ–‡æœ¬)...\nOutput:"
        }, 
        {
            "role": "assistant", 
            "content": "To convert liters to US gallons, we use the conversion factor..."
        }
    ]
}

diagnose_masking(real_data)